
# Comments Moderation Service

## Описание

Этот сервис предоставляет API для классификации токсичных комментариев с использованием предобученной модели NLP. Сервис использует **FastAPI** для создания API, **PyTorch** для работы с моделями и **Transformers** для использования предобученных моделей BERT. Он анализирует текстовые данные и возвращает оценку токсичности.

## Стек технологий

**-** **FastAPI**: Для создания высокопроизводительных API.

**-** **PyTorch**: Для работы с моделями машинного обучения.

**-** **Transformers**: Для использования предобученных моделей, таких как BERT.

**-** **Uvicorn**: Для запуска FastAPI сервера.

## Установка

Следуйте этим шагам, чтобы установить и запустить сервис на вашем локальном компьютере:

### 1. Клонирование репозитория

Клонируйте репозиторий с помощью Git:

```bash
git clone https://github.com/your-repo/comments-moderation-service.git
```

### **2. Установка зависимостей**

Перейдите в директорию проекта и установите все необходимые зависимости:

```
cd comments-moderation-service

pip install -r requirements.txt
```

### **3. Настройка переменных среды**

Если в проекте используются переменные среды, создайте файл **.env** в корне проекта и определите в нем все необходимые параметры.

Пример содержимого файла **.env**:

```
MODEL_NAME=DeepPavlov/rubert-base-cased
DEVICE=cpu  # или cuda, если у вас есть доступ к GPU
```

### **4. Запуск приложения**

Для запуска сервера используйте команду:

```
uvicorn app.main:app --reload
```

Это запустит сервер на **http://127.0.0.1:8000**, где вы сможете обращаться к API.


## **1. Endpoint для проверки токсичности**

 **URL: /predict

 **Метод** : **POST**

 **Описание** : Принимает текстовый комментарий и возвращает результат анализа токсичности.

 **Пример запроса** :

```
curl -X 'POST' \
  'http://127.0.0.1:8000/predict' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "text": "твой видос параша, удали канал"
}'
```

**Пример ответа** :

```
{
  "label": "toxic"
}
```

### **Формат выходных данных**

Ответ будет содержать поле **label**, указывающее на токсичность текста. Возможные значения:

* "toxic" — токсичный комментарий.

* "non-toxic" — нетоксичный комментарий.
